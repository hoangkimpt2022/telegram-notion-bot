# app.py
# Production-ready Telegram <-> Notion automation
# Features:
# - Flask webhook /telegram_webhook (also supports /webhook)
# - Commands: "<key>", "<key> <n>", "<key> x√≥a", "<key> ƒë√°o", "undo", /cancel
# - mark: mark n oldest unchecked items (if input "3" -> mark 1..3 oldest)
# - archive: archive matched pages (checked+unchecked)
# - dao (ƒë√°o): archive & create pages in NOTION_DATABASE_ID and create L√£i page in LA_NOTION_DATABASE_ID
# - pending confirmations, progress messages, undo stack (in-memory)
# - robust extraction for Notion properties (title, rich_text, number, date, checkbox, rollup, formula)
# - safe retries for Notion create/patch

import os
import time
import re
import math
import json
import traceback
import threading
import requests
import unicodedata
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
from flask import Flask, request, jsonify

# ------------- CONFIG -------------
NOTION_TOKEN = os.getenv("NOTION_TOKEN", "")
NOTION_VERSION = os.getenv("NOTION_VERSION", "2022-06-28")
NOTION_HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}" if NOTION_TOKEN else "",
    "Notion-Version": NOTION_VERSION,
    "Content-Type": "application/json",
}
NOTION_DATABASE_ID = os.getenv("NOTION_DATABASE_ID", "")
TARGET_NOTION_DATABASE_ID = os.getenv("TARGET_NOTION_DATABASE_ID", "")
LA_NOTION_DATABASE_ID = os.getenv("LA_NOTION_DATABASE_ID", "")

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN", "")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "")  # optional: restrict bot to one chat id

WAIT_CONFIRM = int(os.getenv("WAIT_CONFIRM", "120"))  # seconds
PATCH_DELAY = float(os.getenv("PATCH_DELAY", "0.3"))  # seconds delay between Notion calls
MAX_QUERY_PAGE_SIZE = int(os.getenv("MAX_QUERY_PAGE_SIZE", "100"))

# ------------- IN-MEM STATE -------------
pending_confirm: Dict[str, Dict[str, Any]] = {}  # chat_id_str -> {type, ...}
undo_stack: Dict[str, List[Dict[str, Any]]] = {}  # chat_id_str -> list of actions for undo (in-memory)

# ------------- UTIL: Telegram send -------------
def send_telegram(chat_id: str, text: str):
    """Send message to Telegram or print if token not set."""
    try:
        if TELEGRAM_TOKEN:
            url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
            data = {"chat_id": chat_id, "text": text, "disable_web_page_preview": True}
            requests.post(url, data=data, timeout=8)
        else:
            print(f"[TG:{chat_id}] {text}")
    except Exception as e:
        print("send_telegram error:", e)

def send_long_text(chat_id: str, text: str):
    """Chunk long text for Telegram."""
    max_len = 3000
    for i in range(0, len(text), max_len):
        send_telegram(chat_id, text[i:i+max_len])

def send_progress(chat_id: str, step: int, total: int, label: str):
    """Simple throttled progress messages."""
    try:
        if total == 0:
            return
        if step == 1 or step % 10 == 0 or step == total:
            send_telegram(chat_id, f"‚è±Ô∏è {label}: {step}/{total} ...")
    except Exception as e:
        print("send_progress error:", e)

# ------------- UTIL: Notion API wrappers -------------
def _notion_post(url: str, json_body: dict, attempts: int = 3, timeout: int = 15):
    """POST with simple retry."""
    for i in range(attempts):
        try:
            r = requests.post(url, headers=NOTION_HEADERS, json=json_body, timeout=timeout)
            if r.status_code in (200, 201):
                return True, r.json()
            # transient server errors -> retry
            if r.status_code >= 500:
                time.sleep(1 + i)
                continue
            return False, {"status": r.status_code, "text": r.text}
        except Exception as e:
            last_exc = e
            time.sleep(1 + i)
    return False, str(last_exc)

def _notion_patch(url: str, json_body: dict, attempts: int = 3, timeout: int = 12):
    """PATCH with simple retry."""
    for i in range(attempts):
        try:
            r = requests.patch(url, headers=NOTION_HEADERS, json=json_body, timeout=timeout)
            if r.status_code in (200, 204):
                try:
                    return True, r.json() if r.text else {}
                except:
                    return True, {}
            if r.status_code >= 500:
                time.sleep(1 + i)
                continue
            return False, {"status": r.status_code, "text": r.text}
        except Exception as e:
            last_exc = e
            time.sleep(1 + i)
    return False, str(last_exc)

def query_database_all(database_id: str, page_size: int = MAX_QUERY_PAGE_SIZE) -> List[Dict[str, Any]]:
    """Query all pages in a database using pagination (Notion /query)."""
    if not NOTION_TOKEN or not database_id:
        print("query_database_all missing config")
        return []
    results: List[Dict[str, Any]] = []
    try:
        url = f"https://api.notion.com/v1/databases/{database_id}/query"
        payload = {"page_size": page_size}
        r = requests.post(url, headers=NOTION_HEADERS, json=payload, timeout=20)
        if r.status_code != 200:
            print("query_database_all failed:", r.status_code, r.text)
            return []
        data = r.json()
        results.extend(data.get("results", []))
        while data.get("has_more"):
            payload["start_cursor"] = data.get("next_cursor")
            r = requests.post(url, headers=NOTION_HEADERS, json=payload, timeout=20)
            if r.status_code != 200:
                print("pagination failed:", r.status_code, r.text)
                break
            data = r.json()
            results.extend(data.get("results", []))
        return results
    except Exception as e:
        print("query_database_all exception:", e)
        return []

def create_page_in_db(database_id: str, properties: Dict[str, Any]) -> Tuple[bool, Any]:
    if not NOTION_TOKEN or not database_id:
        return False, "Notion config missing"
    url = "https://api.notion.com/v1/pages"
    body = {"parent": {"database_id": database_id}, "properties": properties}
    return _notion_post(url, body)

def archive_page(page_id: str) -> Tuple[bool, str]:
    if not NOTION_TOKEN or not page_id:
        return False, "Notion config missing"
    url = f"https://api.notion.com/v1/pages/{page_id}"
    body = {"archived": True}
    return _notion_patch(url, body)

def update_page_properties(page_id: str, properties: Dict[str, Any]) -> Tuple[bool, Any]:
    if not NOTION_TOKEN or not page_id:
        return False, "Notion config missing"
    url = f"https://api.notion.com/v1/pages/{page_id}"
    body = {"properties": properties}
    return _notion_patch(url, body)

# ------------- UTIL: property extraction & parsing -------------
def normalize_text(s: Optional[str]) -> str:
    if not s:
        return ""
    s = str(s).strip().lower()
    nf = unicodedata.normalize("NFD", s)
    return "".join(c for c in nf if unicodedata.category(c) != "Mn")

def extract_plain_text_from_rich_text(arr: List[Dict[str, Any]]) -> str:
    if not arr:
        return ""
    return "".join([x.get("plain_text", "") for x in arr if isinstance(x, dict)])

def find_prop_key(props: Dict[str, Any], name_like: str) -> Optional[str]:
    if not props:
        return None
    for k in props.keys():
        if normalize_text(k) == normalize_text(name_like):
            return k
    # fallback: contains
    for k in props.keys():
        if normalize_text(name_like) in normalize_text(k):
            return k
    return None

def extract_prop_text(props: Dict[str, Any], key_like: str) -> str:
    """
    Robust extractor for Notion property values.
    Supports: title, rich_text, number, date, checkbox, select, multi_select, relation, formula, rollup.
    Returns string (empty if not present).
    """
    if not props:
        return ""
    k = find_prop_key(props, key_like)
    if not k:
        return ""
    prop = props.get(k, {}) or {}
    ptype = prop.get("type")

    # FORMULA
    if ptype == "formula":
        formula = prop.get("formula", {})
        ftype = formula.get("type")
        if ftype == "number" and formula.get("number") is not None:
            return str(formula.get("number"))
        if ftype == "string" and formula.get("string"):
            return str(formula.get("string"))
        if ftype == "boolean" and formula.get("boolean") is not None:
            return "1" if formula.get("boolean") else "0"
        if ftype == "date" and formula.get("date"):
            return formula["date"].get("start", "")
        return ""

    # ROLLUP
    if ptype == "rollup":
        roll = prop.get("rollup", {})
        rtype = roll.get("type")
        if rtype == "number" and roll.get("number") is not None:
            return str(roll.get("number"))
        if rtype == "array":
            arr = roll.get("array", [])
            if arr:
                first = arr[0]
                # attempt to extract number or text
                if isinstance(first, dict):
                    if "number" in first and first.get("number") is not None:
                        return str(first.get("number"))
                    # for title-like
                    if "title" in first:
                        return extract_plain_text_from_rich_text(first.get("title", []))
                    if "plain_text" in first:
                        return first.get("plain_text", "")
                return str(first)
        return ""

    # TITLE
    if ptype == "title":
        return extract_plain_text_from_rich_text(prop.get("title", []))
    if ptype == "rich_text":
        return extract_plain_text_from_rich_text(prop.get("rich_text", []))
    if ptype == "number":
        return str(prop.get("number"))
    if ptype == "date":
        d = prop.get("date", {}) or {}
        return d.get("start", "") or ""
    if ptype == "checkbox":
        return "1" if prop.get("checkbox") else "0"
    if ptype == "select":
        sel = prop.get("select") or {}
        return sel.get("name", "")
    if ptype == "multi_select":
        arr = prop.get("multi_select") or []
        return ", ".join(a.get("name", "") for a in arr)
    if ptype == "relation":
        rel = prop.get("relation") or []
        if rel:
            # return first relation id
            return rel[0].get("id", "")
    return ""

def parse_money_from_text(s: Optional[str]) -> float:
    """Extract first number from string; return 0.0 if none."""
    if s is None:
        return 0.0
    try:
        s2 = str(s).replace(",", "")
        m = re.search(r"-?\d+\.?\d*", s2)
        if not m:
            return 0.0
        return float(m.group(0))
    except Exception:
        return 0.0

# ------------- FINDERS & LIST BUILDERS -------------
def find_target_matches(keyword: str, db_id: str = TARGET_NOTION_DATABASE_ID) -> List[Tuple[str, str, Dict[str, Any]]]:
    """Find entries in TARGET DB where title contains keyword (case-insensitive)."""
    if not db_id:
        return []
    kw = normalize_text(keyword)
    pages = query_database_all(db_id, page_size=MAX_QUERY_PAGE_SIZE)
    matches = []
    for p in pages:
        props = p.get("properties", {})
        title = extract_prop_text(props, "Name") or extract_prop_text(props, "Title") or ""
        if kw in normalize_text(title):
            matches.append((p.get("id"), title, props))
    return matches

def find_calendar_matches(keyword: str) -> List[Tuple[str, str, Optional[str], Dict[str, Any]]]:
    """Return unchecked pages in NOTION_DATABASE_ID matching keyword; sorted by date asc."""
    if not NOTION_DATABASE_ID:
        return []
    kw = normalize_text(keyword)
    pages = query_database_all(NOTION_DATABASE_ID, page_size=MAX_QUERY_PAGE_SIZE)
    matches: List[Tuple[str, str, Optional[str], Dict[str, Any]]] = []
    for p in pages:
        props = p.get("properties", {})
        title = extract_prop_text(props, "Name") or extract_prop_text(props, "Title") or ""
        title_clean = normalize_text(title)
        kw_clean = normalize_text(kw)

        # exact match tr∆∞·ªõc
        if title_clean == kw_clean or title_clean.strip() == kw_clean:
            score = 2
        # b·∫Øt ƒë·∫ßu b·∫±ng keyword (v√≠ d·ª•: "h∆∞∆°ng vip")
        elif title_clean.startswith(kw_clean + " "):
            score = 1
        # kh·ªõp m·ªù th√¨ cho ƒëi·ªÉm th·∫•p h∆°n
        elif kw_clean in title_clean:
            score = 0.5
        else:
            continue
        matches.append((p.get("id"), title, date_iso, props, score))

        # is checked?
        cb_key = find_prop_key(props, "ƒê√£ G√≥p") or find_prop_key(props, "ƒê√£G√≥p") or find_prop_key(props, "Sent") or find_prop_key(props, "Status")
        checked = False
        if cb_key and props.get(cb_key, {}).get("type") == "checkbox":
            checked = bool(props.get(cb_key, {}).get("checkbox"))
        if checked:
            continue
        # ‚úÖ L·∫•y ch√≠nh x√°c c·ªôt "Ng√†y G√≥p"
        date_key = find_prop_key(props, "Ng√†y G√≥p")
        date_iso = None
        if date_key:
            date_field = props.get(date_key, {})
            if date_field.get("type") == "date":
                date_iso = date_field["date"].get("start")
        matches.append((p.get("id"), title, date_iso, props))
    matches.sort(key=lambda x: (-x[4], x[2] or ""))
    return matches

def find_matching_all_pages_in_db(database_id: str, keyword: str, limit: int = 2000) -> List[Tuple[str, str, Optional[str]]]:
    """Helper: return all pages in a DB where title contains keyword (both checked/unchecked)."""
    if not database_id:
        return []
    kw = normalize_text(keyword)
    pages = query_database_all(database_id, page_size=MAX_QUERY_PAGE_SIZE)
    out = []
    for p in pages:
        props = p.get("properties", {})
        title = extract_prop_text(props, "Name") or extract_prop_text(props, "Title") or ""
        if kw in normalize_text(title):
            date_key = find_prop_key(props, "Ng√†y") or find_prop_key(props, "Date")
            date_iso = None
            if date_key and props.get(date_key, {}).get("date"):
                date_iso = props[date_key]["date"].get("start")
            out.append((p.get("id"), title, date_iso))
            if len(out) >= limit:
                break
    return out

# ------------- DAO preview & calculations -------------
def dao_preview_text_from_props(title: str, props: Dict[str, Any]) -> Tuple[bool, str]:
    """
    Prepare preview string for ƒë√°o action.
    Returns (can_do, message)
    """
    try:
        total_text = extract_prop_text(props, "ƒê√°o/th·ªëi") or extract_prop_text(props, "ƒê√°o") or ""
        total_val = parse_money_from_text(total_text)
        per_day = parse_money_from_text(extract_prop_text(props, "G ng√†y") or extract_prop_text(props, "Gng√†y") or "")
        days_before = int(float(extract_prop_text(props, "ng√†y tr∆∞·ªõc") or "0"))
        pre_amount = parse_money_from_text(extract_prop_text(props, "tr∆∞·ªõc") or "")
        if pre_amount == 0:
            msg = f"üîî ƒë√°o l·∫°i cho: {title} - T·ªïng ƒë√°o: ‚úÖ {int(total_val) if total_val else 'N/A'}\n\nKh√¥ng L·∫•y tr∆∞·ªõc"
            return True, msg
        # compute take_days
        if days_before and days_before > 0:
            take_days = days_before
        else:
            take_days = int(math.ceil(pre_amount / per_day)) if per_day else 0
        if take_days <= 0:
            return False, f"‚ö†Ô∏è Kh√¥ng x√°c ƒë·ªãnh s·ªë ng√†y h·ª£p l·ªá cho {title}. (per_day={per_day}, pre_amount={pre_amount}, days_before={days_before})"
        lines = [
            f"üîî ƒë√°o l·∫°i cho: {title} - T·ªïng ƒë√°o: ‚úÖ {int(total_val) if total_val else 'N/A'}",
            "",
            f"L·∫•y tr∆∞·ªõc: {take_days} ng√†y" if take_days else "Kh√¥ng L·∫•y tr∆∞·ªõc",
            f"G ng√†y: {int(per_day) if per_day else 0}",
            f"Ng√†y tr∆∞·ªõc: {days_before}",
            f"Tr∆∞·ªõc: {int(pre_amount) if pre_amount else 0}",
            "",
            "Danh s√°ch ng√†y d·ª± ki·∫øn t·∫°o (b·∫Øt ƒë·∫ßu t·ª´ ng√†y mai):",
        ]
        start = datetime.now().date() + timedelta(days=1)
        for i in range(take_days):
            lines.append((start + timedelta(days=i)).isoformat())
        lines.append("")
        lines.append(f"G·ª≠i /ok ƒë·ªÉ t·∫°o {take_days} page trong {WAIT_CONFIRM}s, ho·∫∑c /cancel.")
        return True, "\n".join(lines)
    except Exception as e:
        return False, f"Preview error: {e}"

# ------------- ACTIONS: mark / undo -------------
def count_checked_unchecked(keyword: str) -> Tuple[int, int]:
    results = query_database_all(NOTION_DATABASE_ID, page_size=MAX_QUERY_PAGE_SIZE)
    checked = 0
    unchecked = 0
    kw = normalize_text(keyword)
    for p in results:
        props = p.get("properties", {})
        title = extract_prop_text(props, "Name") or ""
        if kw in normalize_text(title):
            key = find_prop_key(props, "ƒê√£ G√≥p") or find_prop_key(props, "Sent") or find_prop_key(props, "Status")
            checked_flag = False
            if key and props.get(key, {}).get("type") == "checkbox":
                checked_flag = bool(props.get(key, {}).get("checkbox"))
            if checked_flag:
                checked += 1
            else:
                unchecked += 1
    return checked, unchecked

def mark_pages_by_indices(chat_id: str, keyword: str, matches: List[Tuple[str, str, Optional[str], Dict[str, Any]]], indices: List[int]) -> Dict[str, Any]:
    """
    Mark pages by indices. Business rule:
    - If indices == [n] and n > 1 => expand to select 1..n (oldest first).
    """
    succeeded = []
    failed = []
    if len(indices) == 1 and indices[0] > 1:
        n = indices[0]
        indices = list(range(1, min(n, len(matches)) + 1))
    for idx in indices:
        if idx < 1 or idx > len(matches):
            failed.append((idx, "index out of range"))
            continue
        pid, title, date_iso, props = matches[idx - 1]
        try:
            cb_key = find_prop_key(props, "ƒê√£ G√≥p") or find_prop_key(props, "Sent") or find_prop_key(props, "Status")
            update_props = {}
            if cb_key:
                update_props[cb_key] = {"checkbox": True}
            else:
                update_props["ƒê√£ G√≥p"] = {"checkbox": True}
            ok, res = update_page_properties(pid, update_props)
            if ok:
                succeeded.append((pid, title, date_iso))
                undo_stack.setdefault(str(chat_id), []).append({"action": "mark", "page_id": pid})
            else:
                failed.append((pid, res))
        except Exception as e:
            failed.append((pid, str(e)))
    return {"ok": len(failed) == 0, "succeeded": succeeded, "failed": failed}

def undo_last(chat_id: str, count: int = 1):
    ck = str(chat_id)
    stack = undo_stack.get(ck, [])
    if not stack:
        send_telegram(chat_id, "Kh√¥ng c√≥ h√†nh ƒë·ªông ƒë·ªÉ undo.")
        return
    reverted = 0
    failed = 0
    for _ in range(min(count, len(stack))):
        rec = stack.pop()
        if rec.get("action") == "mark":
            pid = rec.get("page_id")
            try:
                ok, res = update_page_properties(pid, {"ƒê√£ G√≥p": {"checkbox": False}})
                if ok:
                    reverted += 1
                else:
                    failed += 1
            except Exception:
                failed += 1
    undo_stack[ck] = stack
    send_telegram(chat_id, f"‚ôªÔ∏è Undo done. Reverted {reverted} items. Failed: {failed}")
    send_telegram(chat_id, f"üîé Kh√°ch h√†ng: undone actions for chat {chat_id}")

# ------------- ACTIONS: archive -------------
def handle_command_archive(chat_id: str, keyword: str, auto_confirm_all: bool = True) -> Dict[str, Any]:
    """
    Archive all pages in NOTION_DATABASE_ID matching keyword.
    If auto_confirm_all True -> do it immediately (used by dao).
    If called interactively, use the handler in handle_incoming_message to present options.
    """
    try:
        matches = find_matching_all_pages_in_db(NOTION_DATABASE_ID, keyword, limit=5000)
        total = len(matches)
        send_telegram(chat_id, f"üßπ ƒêang x√≥a {total} ng√†y c·ªßa {keyword} (check + uncheck)...")
        if total == 0:
            send_telegram(chat_id, f"‚úÖ Kh√¥ng t√¨m th·∫•y m·ª•c c·∫ßn x√≥a cho '{keyword}'.")
            return {"ok": True, "deleted": [], "failed": []}
        deleted = []
        failed = []
        for i, (pid, title, date_iso) in enumerate(matches, start=1):
            send_progress(chat_id, i, total, f"üóëÔ∏è ƒêang x√≥a {keyword}")
            ok, msg = archive_page(pid)
            if ok:
                deleted.append(pid)
            else:
                failed.append((pid, msg))
            time.sleep(PATCH_DELAY)
        send_telegram(chat_id, f"‚úÖ ƒê√£ x√≥a xong {len(deleted)}/{total} m·ª•c c·ªßa {keyword}.")
        if failed:
            send_telegram(chat_id, f"‚ö†Ô∏è C√≥ {len(failed)} m·ª•c x√≥a l·ªói, xem logs.")
        return {"ok": True, "deleted": deleted, "failed": failed}
    except Exception as e:
        traceback.print_exc()
        send_telegram(chat_id, f"‚ùå L·ªói archive: {e}")
        return {"ok": False, "error": str(e)}

# ------------- ACTIONS: create lai page -------------
def create_lai_page(chat_id: int, title: str, lai_amount: float, relation_id: str):
    """
    T·∫°o 1 page L√£i trong LA_NOTION_DATABASE_ID v·ªõi:
     - Name = title
     - L√£i = l·∫•y s·ªë ti·ªÅn t·ª´ c·ªôt "Lai l·ªãch g" b√™n TARGET_NOTION_DATABASE_ID
     - Ng√†y G√≥p = ng√†y h√¥m nay
     - L·ªãch G = relation tr·ªè v·ªÅ page g·ªëc
    """
    try:
        today = datetime.now().date().isoformat()

        props_payload = {
            "Name": {"title": [{"type": "text", "text": {"content": title}}]},
            "L√£i": {"number": lai_amount},
            "Ng√†y G√≥p": {"date": {"start": today}},
            "L·ªãch G": {"relation": [{"id": relation_id}]}
        }

        url = "https://api.notion.com/v1/pages"
        body = {"parent": {"database_id": LA_NOTION_DATABASE_ID}, "properties": props_payload}
        r = requests.post(url, headers=NOTION_HEADERS, json=body, timeout=15)

        if r.status_code in (200, 201):
            send_telegram(chat_id, f"üí∞ ƒê√£ t·∫°o L√£i cho {title}: {lai_amount:,.0f}")
        else:
            send_telegram(chat_id, f"‚ö†Ô∏è T·∫°o L√£i l·ªói: {r.status_code} - {r.text}")

    except Exception as e:
        send_telegram(chat_id, f"‚ùå L·ªói t·∫°o L√£i cho {title}: {str(e)}")


# ------------- DAO flow (x√≥a + t·∫°o pages + create lai) -------------
def dao_create_pages_from_props(chat_id: int, source_page_id: str, props: Dict[str, Any]):
    """
    X·ª≠ l√Ω ƒë√°o:
     - archive to√†n b·ªô page c·ªßa 'key' trong NOTION_DATABASE_ID (checked + unchecked)
     - t·∫°o `take_days` page m·ªõi b·∫Øt ƒë·∫ßu t·ª´ ng√†y mai, m·ªói page c√≥ ƒê√£ G√≥p = True
     - t·∫°o 1 page L√£i trong LA_NOTION_DATABASE_ID (n·∫øu c√≥ gi√° tr·ªã L√£i)
     - b√°o ti·∫øn tr√¨nh chi ti·∫øt qua Telegram
    """
    try:
        title = extract_prop_text(props, "Name") or "UNKNOWN"
        total_text = extract_prop_text(props, "ƒê√°o/th·ªëi")
        total_val = parse_money_from_text(total_text) or 0

        # ƒë·ªçc c√°c tr∆∞·ªùng c·∫ßn thi·∫øt t·ª´ DB ƒë√°o
        per_day = parse_money_from_text(extract_prop_text(props, "G ng√†y")) or 0
        days_before = parse_money_from_text(extract_prop_text(props, "ng√†y tr∆∞·ªõc")) or 0
        pre_amount = parse_money_from_text(extract_prop_text(props, "tr∆∞·ªõc")) or 0

        # ki·ªÉm tra ƒëi·ªÅu ki·ªán
        if pre_amount == 0:
            send_telegram(chat_id, f"üîî ƒë√°o l·∫°i cho: {title} - T·ªïng ƒë√°o: ‚úÖ {int(total_val)}\n\nKh√¥ng L·∫•y tr∆∞·ªõc")
            return

        take_days = int(days_before) if days_before else int(math.ceil(pre_amount / per_day)) if per_day else 0
        if take_days <= 0:
            send_telegram(chat_id, f"‚ö†Ô∏è Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c s·ªë ng√†y h·ª£p l·ªá cho {title} (per_day={per_day}, pre_amount={pre_amount})")
            return

        # --- 1Ô∏è‚É£ X√ìA PAGE C≈® ---
        all_pages = query_database_all(NOTION_DATABASE_ID, page_size=500)
        kw = title.strip().lower()
        matched = []
        for p in all_pages:
            props_p = p.get("properties", {})
            name_p = extract_prop_text(props_p, "Name") or ""
            if kw in name_p.lower():
                matched.append(p.get("id"))
        total_to_delete = len(matched)
        send_telegram(chat_id, f"üßπ ƒêang x√≥a {total_to_delete} ng√†y c·ªßa {title} (check + uncheck)...")

        deleted = 0
        for i, pid in enumerate(matched, start=1):
            try:
                archive_page(pid)
                deleted += 1
            except Exception as e:
                send_telegram(chat_id, f"‚ö†Ô∏è L·ªói x√≥a {pid}: {str(e)}")
            time.sleep(PATCH_DELAY)
        send_telegram(chat_id, f"‚úÖ ƒê√£ x√≥a xong {deleted}/{total_to_delete} m·ª•c c·ªßa {title}.")

        # --- 2Ô∏è‚É£ T·∫†O PAGE M·ªöI ---
        start = datetime.now().date() + timedelta(days=1)
        created = []
        send_telegram(chat_id, f"üõ†Ô∏è ƒêang t·∫°o {take_days} ng√†y m·ªõi cho {title} (b·∫Øt ƒë·∫ßu t·ª´ ng√†y mai)...")

        for i in range(1, take_days + 1):
            d = start + timedelta(days=i - 1)
            props_payload = {
                "Name": {"title": [{"type": "text", "text": {"content": title}}]},
                "Ng√†y G√≥p": {"date": {"start": d.isoformat()}},
                "Ti·ªÅn": {"number": per_day},
                "ƒê√£ G√≥p": {"checkbox": True},
                "L·ªãch G": {"relation": [{"id": source_page_id}]},
            }

            try:
                url = "https://api.notion.com/v1/pages"
                body = {"parent": {"database_id": NOTION_DATABASE_ID}, "properties": props_payload}
                r = requests.post(url, headers=NOTION_HEADERS, json=body, timeout=20)
                if r.status_code in (200, 201):
                    created.append(r.json())
                    send_progress(chat_id, i, take_days, f"üìÖ T·∫°o ng√†y {d} cho {title}")
                else:
                    send_telegram(chat_id, f"‚ö†Ô∏è T·∫°o l·ªói {r.status_code}: {r.text}")
            except Exception as e:
                send_telegram(chat_id, f"‚ö†Ô∏è L·ªói t·∫°o ng√†y {i}: {str(e)}")
            time.sleep(PATCH_DELAY)

        send_telegram(chat_id, f"‚úÖ ƒê√£ t·∫°o {len(created)} ng√†y m·ªõi cho {title} (ƒë√£ check 'ƒê√£ G√≥p').")

                # --- 3Ô∏è‚É£ T·∫†O L√ÉI (n·∫øu c√≥) ---
        lai_text = extract_prop_text(props, "Lai l·ªãch g") or extract_prop_text(props, "L√£i") or extract_prop_text(props, "Lai") or ""
        lai_amt = parse_money_from_text(lai_text) or 0
        if LA_NOTION_DATABASE_ID and lai_amt > 0:
            send_telegram(chat_id, f"üí∏ Ti·∫øp t·ª•c t·∫°o L√£i cho {title}...")
            relation_target_id = created[0].get("id", source_page_id) if created else source_page_id
            create_lai_page(chat_id, title, lai_amt, relation_target_id)
        else:
            send_telegram(chat_id, f"‚ÑπÔ∏è Kh√¥ng c√≥ gi√° tr·ªã L√£i ho·∫∑c ch∆∞a c·∫•u h√¨nh LA_NOTION_DATABASE_ID. B·ªè qua t·∫°o L√£i.")
    
    except Exception as e:
        send_telegram(chat_id, f"‚ùå L·ªói ti·∫øn tr√¨nh ƒë√°o cho {title}: {str(e)}")
        traceback.print_exc()
        return

# ------------- PENDING / SELECTION PROCESSING -------------
def parse_user_selection_text(sel_text: str, found_len: int) -> List[int]:
    """Parse selection input like '1', '1,2', '1-3', 'all', or '3' (meaning 1..3)."""
    s = sel_text.strip().lower()
    if s in ("all", "t·∫•t c·∫£", "tat ca"):
        return list(range(1, found_len + 1))
    parts = s.split(",")
    selected = []
    for p in parts:
        p = p.strip()
        if "-" in p:
            try:
                a, b = p.split("-", 1)
                a_i = int(a); b_i = int(b)
                for i in range(min(a_i, b_i), max(a_i, b_i) + 1):
                    selected.append(i)
            except:
                pass
        else:
            try:
                n = int(p)
                if n > 1 and found_len >= n:
                    selected.extend(list(range(1, n + 1)))
                else:
                    selected.append(n)
            except:
                pass
    selected = sorted(list(dict.fromkeys([i for i in selected if isinstance(i, int)])))
    return selected

def process_pending_selection_for_dao(chat_id: str, raw: str):
    key = str(chat_id)
    data = pending_confirm.get(key)
    if not data:
        send_telegram(chat_id, "Kh√¥ng c√≥ thao t√°c ƒëang ch·ªù.")
        return
    try:
        if data.get("type") == "dao_choose":
            matches = data.get("matches", [])
            indices = parse_user_selection_text(raw, len(matches))
            if not indices:
                send_telegram(chat_id, "Kh√¥ng nh·∫≠n ƒë∆∞·ª£c l·ª±a ch·ªçn h·ª£p l·ªá.")
                return
            chosen = []
            for idx in indices:
                if 1 <= idx <= len(matches):
                    pid, title, props = matches[idx - 1]
                    chosen.append((pid, title, props))
            for pid, title, props in chosen:
                send_telegram(chat_id, f"‚úÖ ƒêang th·ª±c hi·ªán ƒë√°o cho {title} ...")
                dao_create_pages_from_props(chat_id, pid, props)
            del pending_confirm[key]
            return
        if data.get("type") == "dao_confirm":
            if raw.strip().lower() in ("/cancel", "cancel", "h·ªßy", "huy"):
                del pending_confirm[key]
                send_telegram(chat_id, "ƒê√£ h·ªßy thao t√°c ƒë√°o.")
                return
            if raw.strip().lower() in ("ok", "/ok", "yes", "ƒë·ªìng √Ω", "dong y"):
                source_page_id = data.get("source_page_id")
                props = data.get("props")
                dao_create_pages_from_props(chat_id, source_page_id, props)
                del pending_confirm[key]
                return
            send_telegram(chat_id, "G·ª≠i /ok ƒë·ªÉ th·ª±c hi·ªán ho·∫∑c /cancel ƒë·ªÉ h·ªßy.")
            return
    except Exception as e:
        traceback.print_exc()
        send_telegram(chat_id, f"‚ùå L·ªói x·ª≠ l√Ω l·ª±a ch·ªçn: {e}")
        if key in pending_confirm:
            del pending_confirm[key]

def process_pending_selection(chat_id: str, raw: str):
    key = str(chat_id)
    data = pending_confirm.get(key)
    if not data:
        send_telegram(chat_id, "Kh√¥ng c√≥ thao t√°c ƒëang ch·ªù.")
        return
    try:
        if raw.strip().lower() in ("/cancel", "cancel", "h·ªßy", "huy"):
            del pending_confirm[key]
            send_telegram(chat_id, "ƒê√£ h·ªßy thao t√°c ƒëang ch·ªù.")
            return
        matches = data.get("matches", [])
        indices = parse_user_selection_text(raw, len(matches))
        if not indices:
            send_telegram(chat_id, "Kh√¥ng nh·∫≠n ƒë∆∞·ª£c l·ª±a ch·ªçn h·ª£p l·ªá.")
            return
        action = data.get("type")
        if action == "mark":
            keyword = data.get("keyword")
            res = mark_pages_by_indices(chat_id, keyword, matches, indices)
            if res.get("succeeded"):
                txt = "‚úÖ ƒê√£ ƒë√°nh d·∫•u:\n"
                for pid, title, date_iso in res["succeeded"]:
                    ds = date_iso[:10] if date_iso else "-"
                    txt += f"{ds} ‚Äî {title}\n"
                send_long_text(chat_id, txt)
            if res.get("failed"):
                send_telegram(chat_id, f"‚ö†Ô∏è L·ªói khi ƒë√°nh d·∫•u: {res['failed']}")
            checked, unchecked = count_checked_unchecked(keyword)
            send_telegram(chat_id, f"‚úÖ ƒê√£ t√≠ch: {checked}\n\nüü° Ch∆∞a t√≠ch: {unchecked}")
            del pending_confirm[key]
            return
        if action == "archive_select":
            for idx in indices:
                if 1 <= idx <= len(matches):
                    pid, title, date_iso = matches[idx - 1]
                    handle_command_archive(chat_id, title)
            del pending_confirm[key]
            return
    except Exception as e:
        traceback.print_exc()
        send_telegram(chat_id, f"‚ùå L·ªói x·ª≠ l√Ω l·ª±a ch·ªçn: {e}")
        if key in pending_confirm:
            del pending_confirm[key]

# ------------- Command parsing & main handler -------------
def parse_user_command(raw: str) -> Tuple[str, int, str]:
    txt = raw.strip()
    low = txt.lower()
    parts = txt.split()
    if not parts:
        return "", 0, "unknown"
    if low in ("undo",):
        return "", 0, "undo"
    if low.endswith(" ƒë√°o") or low.endswith(" dao"):
        kw = txt.rsplit(None, 1)[0]
        return kw, 0, "dao"
    if low.endswith(" x√≥a") or low.endswith(" xoa"):
        kw = txt.rsplit(None, 1)[0]
        return kw, 0, "archive"
    keyword = parts[0]
    action = "mark"
    count = 0
    if len(parts) >= 2:
        sec = parts[1]
        if sec.isdigit():
            count = int(sec)
    return keyword, count, action

def handle_incoming_message(chat_id: int, text: str):
    """
    Main entry point for Telegram messages.
    """
    try:
        # optional restrict by chat id
        if TELEGRAM_CHAT_ID and str(chat_id) != str(TELEGRAM_CHAT_ID):
            send_telegram(chat_id, "Bot ch∆∞a ƒë∆∞·ª£c ph√©p nh·∫≠n l·ªánh t·ª´ chat n√†y.")
            return
        raw = text.strip()
        if not raw:
            send_telegram(chat_id, "Vui l√≤ng g·ª≠i l·ªánh ho·∫∑c t·ª´ kho√°.")
            return
        low = raw.lower()

        # if pending confirm exists -> route selection handling
        if str(chat_id) in pending_confirm:
            if low in ("/cancel", "cancel", "h·ªßy", "huy"):
                del pending_confirm[str(chat_id)]
                send_telegram(chat_id, "ƒê√£ h·ªßy thao t√°c ƒëang ch·ªù.")
                return
            pc = pending_confirm[str(chat_id)]
            if pc.get("type") in ("dao_choose", "dao_confirm"):
                threading.Thread(target=process_pending_selection_for_dao, args=(chat_id, raw), daemon=True).start()
                return
            threading.Thread(target=process_pending_selection, args=(chat_id, raw), daemon=True).start()
            return

        if low in ("/cancel", "cancel", "h·ªßy", "huy"):
            send_telegram(chat_id, "Kh√¥ng c√≥ thao t√°c ƒëang ch·ªù. /cancel ignored.")
            return

        keyword, count, action = parse_user_command(raw)

        if action == "undo":
            send_telegram(chat_id, "ƒêang t√¨m v√† undo...")
            threading.Thread(target=undo_last, args=(chat_id, 1), daemon=True).start()
            return

        if action == "archive":
            kw = keyword
            # interactive archive: list all matched pages and ask selection or 'all'
            matches = find_matching_all_pages_in_db(NOTION_DATABASE_ID, kw, limit=5000)
            checked, unchecked = count_checked_unchecked(kw)
            header = f"üîé : '{kw}'\n\n‚úÖ ƒê√£ t√≠ch: {checked}\n\nüü° Ch∆∞a t√≠ch: {unchecked}\n\n"
            header += f"‚ö†Ô∏è CH√ö √ù: B·∫°n s·∫Øp archive {len(matches)} m·ª•c ch·ª©a '{kw}'.\n\nG·ª≠i s·ªë (v√≠ d·ª• 1-7) trong {WAIT_CONFIRM}s ƒë·ªÉ ch·ªçn, ho·∫∑c 'all' ƒë·ªÉ archive t·∫•t c·∫£, ho·∫∑c /cancel.\n\n"
            lines = []
            for i, (pid, title, date_iso) in enumerate(matches, start=1):
                ds = date_iso[:10] if date_iso else "-"
                lines.append(f"{i}. [{ds}] {title}")
            send_long_text(chat_id, header + "\n".join(lines))
            pending_confirm[str(chat_id)] = {"type": "archive_select", "keyword": kw, "matches": matches, "expires": time.time() + WAIT_CONFIRM}
            return

        if action == "dao":
            kw = keyword
            matches = find_target_matches(kw)
            if not matches:
                send_telegram(chat_id, f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y '{kw}' trong DB ƒë√°o.")
                return
            if len(matches) > 1:
                header = f"T√¨m th·∫•y {len(matches)} k·∫øt qu·∫£ cho '{kw}'. Ch·ªçn index ƒë·ªÉ ti·∫øp t·ª•c ho·∫∑c g·ª≠i SƒêT ƒë·ªÉ match ch√≠nh x√°c."
                lines = []
                for i, (pid, title, props) in enumerate(matches, start=1):
                    dt = extract_prop_text(props, "ƒê√°o/th·ªëi") or "-"
                    gday = extract_prop_text(props, "G ng√†y") or "-"
                    nb = extract_prop_text(props, "ng√†y tr∆∞·ªõc") or extract_prop_text(props, "# ng√†y tr∆∞·ªõc") or "-"
                    prev = extract_prop_text(props, "tr∆∞·ªõc") or "-"
                    lines.append(f"{i}. {title} ‚Äî ƒê√°o/th·ªëi: {dt} ‚Äî G ng√†y: {gday} ‚Äî # ng√†y tr∆∞·ªõc: {nb} ‚Äî tr∆∞·ªõc: {prev}")
                send_long_text(chat_id, header + "\n\n" + "\n".join(lines))
                pending_confirm[str(chat_id)] = {"type": "dao_choose", "matches": matches, "expires": time.time() + WAIT_CONFIRM}
                send_telegram(chat_id, f"üì§ G·ª≠i s·ªë (v√≠ d·ª• 1 ho·∫∑c 1-3) trong {WAIT_CONFIRM}s ƒë·ªÉ ch·ªçn, ho·∫∑c /cancel.")
                return
            # single match -> preview
            pid, title, props = matches[0]
            can, preview = dao_preview_text_from_props(title, props)
            send_long_text(chat_id, preview)
            if can:
                pending_confirm[str(chat_id)] = {"type": "dao_confirm", "source_page_id": pid, "props": props, "expires": time.time() + WAIT_CONFIRM}
                send_telegram(chat_id, f"‚úÖ C√≥ th·ªÉ ƒë√°o cho '{title}'. G√µ /ok ƒë·ªÉ th·ª±c hi·ªán trong {WAIT_CONFIRM}s ho·∫∑c /cancel ƒë·ªÉ h·ªßy.")
            else:
                send_telegram(chat_id, f"‚ö†Ô∏è Kh√¥ng th·ªÉ th·ª±c hi·ªán ƒë√°o cho '{title}'. Vui l√≤ng ki·ªÉm tra d·ªØ li·ªáu.")
            return

        # default: mark flow
        kw = keyword
        matches = find_calendar_matches(kw)
        checked, unchecked = count_checked_unchecked(kw)
        header = f"üîé : '{kw}'\n\n‚úÖ ƒê√£ t√≠ch: {checked}\n\nüü° Ch∆∞a t√≠ch: {unchecked}\n\n"
        header += f"üì§ G·ª≠i s·ªë ( v√≠ d·ª• 1 ho·∫∑c 1-3 ) trong {WAIT_CONFIRM}s ƒë·ªÉ ch·ªçn, ho·∫∑c /cancel.\n\n"
        if not matches:
            send_telegram(chat_id, f"Kh√¥ng t√¨m th·∫•y m·ª•c n√†o ch∆∞a t√≠ch cho '{kw}'.")
            return
        lines = []
        for i, (pid, title, date_iso, props) in enumerate(matches, start=1):
            ds = date_iso[:10] if date_iso else "-"
            lines.append(f"{i}. [{ds}] {title}")
        send_long_text(chat_id, header + "\n".join(lines))
        pending_confirm[str(chat_id)] = {"type": "mark", "keyword": kw, "matches": matches, "expires": time.time() + WAIT_CONFIRM}
    except Exception as e:
        traceback.print_exc()
        # ‚ö° AUTO-MARK MODE: n·∫øu user g√µ "gam 2" th√¨ t·ª± ƒë·ªông t√≠ch 2 ng√†y ƒë·∫ßu ti√™n
        if count > 0 and matches:
            send_telegram(chat_id, f"‚ö° ƒêang t·ª± ƒë·ªông ƒë√°nh d·∫•u {count} m·ª•c cho '{kw}'...")
            # ch·ªçn n m·ª•c ƒë·∫ßu ti√™n
            indices = list(range(1, min(count, len(matches)) + 1))
            res = mark_pages_by_indices(chat_id, kw, matches, indices)
            if res.get("succeeded"):
                txt = "‚úÖ ƒê√£ ƒë√°nh d·∫•u:\n"
                for pid, title, date_iso in res["succeeded"]:
                    ds = date_iso[:10] if date_iso else "-"
                    txt += f"{ds} ‚Äî {title}\n"
                send_long_text(chat_id, txt)
            if res.get("failed"):
                send_telegram(chat_id, f"‚ö†Ô∏è C√≥ {len(res['failed'])} m·ª•c ƒë√°nh d·∫•u l·ªói.")
            checked, unchecked = count_checked_unchecked(kw)
            send_telegram(chat_id, f"‚úÖ ƒê√£ t√≠ch: {checked}\nüü° Ch∆∞a t√≠ch: {unchecked}")
            return
        send_telegram(chat_id, f"L·ªói x·ª≠ l√Ω: {e}")

# ------------- BACKGROUND: sweep expired pending -------------
def sweep_pending_expirations():
    while True:
        try:
            now = time.time()
            keys = list(pending_confirm.keys())
            for k in keys:
                item = pending_confirm.get(k)
                if item and item.get("expires") and item.get("expires") < now:
                    try:
                        send_telegram(k, "‚è≥ Thao t√°c ch·ªù ƒë√£ h·∫øt h·∫°n.")
                    except:
                        pass
                    del pending_confirm[k]
        except Exception:
            pass
        time.sleep(5)

threading.Thread(target=sweep_pending_expirations, daemon=True).start()

# ------------- FLASK APP / WEBHOOK -------------
# ------------- FLASK APP / WEBHOOK -------------
app = Flask(__name__)

# ‚úÖ Route ki·ªÉm tra app ƒëang ch·∫°y
@app.route("/", methods=["GET"])
def index():
    return "app_final_v4 running ‚úÖ"

# ‚úÖ Route ch√≠nh cho Telegram webhook (v√† d·ª± ph√≤ng)
@app.route("/telegram_webhook", methods=["POST"])
@app.route("/webhook", methods=["POST"])
def telegram_webhook():
    try:
        data = request.get_json(force=True)
    except Exception:
        return jsonify({"ok": False, "error": "invalid json"}), 400

    if not data:
        return jsonify({"ok": False, "error": "no data"}), 400

    message = data.get("message") or data.get("edited_message") or {}
    if not message:
        return jsonify({"ok": True})

    chat = message.get("chat", {})
    chat_id = chat.get("id")
    text = message.get("text") or message.get("caption") or ""

    if chat_id and text:
        threading.Thread(
            target=handle_incoming_message,
            args=(chat_id, text),
            daemon=True
        ).start()

    # ‚úÖ Quan tr·ªçng: tr·∫£ l·∫°i JSON ƒë·ªÉ Telegram bi·∫øt bot ƒë√£ nh·∫≠n
    return jsonify({"ok": True})



# ------------- RUN (local test) -------------
if __name__ == "__main__":
    port = int(os.getenv("PORT", "5000"))
    print("Launching app.py on port", port)
    print("NOTION_DATABASE_ID:", NOTION_DATABASE_ID[:8] + "..." if NOTION_DATABASE_ID else "(none)")
    print("TARGET_NOTION_DATABASE_ID:", TARGET_NOTION_DATABASE_ID[:8] + "..." if TARGET_NOTION_DATABASE_ID else "(none)")
    print("LA_NOTION_DATABASE_ID:", LA_NOTION_DATABASE_ID[:8] + "..." if LA_NOTION_DATABASE_ID else "(none)")
    print("TELEGRAM_TOKEN set?:", bool(TELEGRAM_TOKEN))
    app.run(host="0.0.0.0", port=port)
